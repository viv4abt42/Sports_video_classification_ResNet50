{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import multilabel_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = r'/Users/valeriyavishnevskaya/Downloads/data'\n",
    "outputmodel = r'/Users/valeriyavishnevskaya/Desktop/test/video_classification'\n",
    "oplabelbinarizer = r'/Users/valeriyavishnevskaya/Desktop/test/video_classification/videoclassificationbinarizer'\n",
    "epoch =25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images loaded\n"
     ]
    }
   ],
   "source": [
    "sports_labels = set(['boxing','swimming',\"table_tennis\",\"badminton\",\"football\"])\n",
    "print(\"Images loaded\")\n",
    "pathToImages = list(paths.list_images(datapath))\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "for images in pathToImages:\n",
    "    label = images.split(os.path.sep)[-2]\n",
    "    if label not in sports_labels:\n",
    "        continue\n",
    "    image = cv2.imread(images)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224,224))\n",
    "    data.append(image)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "#hot encoded values as 0,1,2,3,4\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, Y_train, Y_test) = train_test_split(data,labels,test_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingAugmentation = ImageDataGenerator(\n",
    "rotation_range=30,\n",
    "zoom_range=0.15,\n",
    "width_shift_range=0.2,\n",
    "height_shift_range=0.2,\n",
    "shear_range=0.15,\n",
    "horizontal_flip=True,\n",
    "fill_mode=\"nearest\"\n",
    ")\n",
    "validationAugmentation = ImageDataGenerator()\n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "trainingAugmentation.mean = mean\n",
    "validationAugmentation.mean = mean  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers.pooling import AveragePooling2D\n",
    "from keras.applications import ResNet50\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Flatten\n",
    "\n",
    "from keras.layers.core import Dropout\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel = ResNet50(weights=\"imagenet\", include_top= False, input_tensor=Input(shape=(224,224,3)))\n",
    "\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7,7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(512, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(len(lb.classes_), activation=\"softmax\")(headModel)\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "for basemodelLayers in baseModel.layers:\n",
    "    basemodelLayers.trainable = False\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "epoch=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(learning_rate=0.0001, momentum=0.9, decay=1e-4//epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=['accuracy','Precision','Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-e450c13e2be9>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "95/95 [==============================] - 492s 5s/step - loss: 1.6606 - accuracy: 0.3833 - precision: 0.4573 - recall: 0.2561 - val_loss: 0.8826 - val_accuracy: 0.6848 - val_precision: 0.8458 - val_recall: 0.5068\n",
      "Epoch 2/30\n",
      "95/95 [==============================] - 431s 5s/step - loss: 1.0354 - accuracy: 0.5952 - precision: 0.7023 - recall: 0.4763 - val_loss: 0.6262 - val_accuracy: 0.8139 - val_precision: 0.9126 - val_recall: 0.6807\n",
      "Epoch 3/30\n",
      "95/95 [==============================] - 460s 5s/step - loss: 0.7994 - accuracy: 0.7001 - precision: 0.7898 - recall: 0.6001 - val_loss: 0.5169 - val_accuracy: 0.8560 - val_precision: 0.9249 - val_recall: 0.7527\n",
      "Epoch 4/30\n",
      "95/95 [==============================] - 446s 5s/step - loss: 0.6900 - accuracy: 0.7499 - precision: 0.8266 - recall: 0.6636 - val_loss: 0.4561 - val_accuracy: 0.8804 - val_precision: 0.9358 - val_recall: 0.7921\n",
      "Epoch 5/30\n",
      "95/95 [==============================] - 461s 5s/step - loss: 0.6428 - accuracy: 0.7682 - precision: 0.8384 - recall: 0.6925 - val_loss: 0.4187 - val_accuracy: 0.8886 - val_precision: 0.9356 - val_recall: 0.8098\n",
      "Epoch 6/30\n",
      "95/95 [==============================] - 421s 4s/step - loss: 0.5950 - accuracy: 0.7868 - precision: 0.8398 - recall: 0.7157 - val_loss: 0.3862 - val_accuracy: 0.8913 - val_precision: 0.9388 - val_recall: 0.8342\n",
      "Epoch 7/30\n",
      "95/95 [==============================] - 422s 4s/step - loss: 0.5619 - accuracy: 0.7977 - precision: 0.8612 - recall: 0.7317 - val_loss: 0.3666 - val_accuracy: 0.9008 - val_precision: 0.9398 - val_recall: 0.8492\n",
      "Epoch 8/30\n",
      "95/95 [==============================] - 411s 4s/step - loss: 0.5185 - accuracy: 0.8197 - precision: 0.8765 - recall: 0.7635 - val_loss: 0.3401 - val_accuracy: 0.9117 - val_precision: 0.9502 - val_recall: 0.8560\n",
      "Epoch 9/30\n",
      "95/95 [==============================] - 395s 4s/step - loss: 0.5127 - accuracy: 0.8163 - precision: 0.8687 - recall: 0.7649 - val_loss: 0.3409 - val_accuracy: 0.9117 - val_precision: 0.9478 - val_recall: 0.8628\n",
      "Epoch 10/30\n",
      "95/95 [==============================] - 461s 5s/step - loss: 0.4816 - accuracy: 0.8283 - precision: 0.8814 - recall: 0.7775 - val_loss: 0.3286 - val_accuracy: 0.9117 - val_precision: 0.9449 - val_recall: 0.8628\n",
      "Epoch 11/30\n",
      "95/95 [==============================] - 374s 4s/step - loss: 0.4735 - accuracy: 0.8329 - precision: 0.8805 - recall: 0.7855 - val_loss: 0.3139 - val_accuracy: 0.9117 - val_precision: 0.9472 - val_recall: 0.8777\n",
      "Epoch 12/30\n",
      "95/95 [==============================] - 365s 4s/step - loss: 0.4436 - accuracy: 0.8373 - precision: 0.8845 - recall: 0.7881 - val_loss: 0.3022 - val_accuracy: 0.9158 - val_precision: 0.9503 - val_recall: 0.8832\n",
      "Epoch 13/30\n",
      "95/95 [==============================] - 367s 4s/step - loss: 0.4283 - accuracy: 0.8529 - precision: 0.8990 - recall: 0.8070 - val_loss: 0.2987 - val_accuracy: 0.9144 - val_precision: 0.9466 - val_recall: 0.8913\n",
      "Epoch 14/30\n",
      "95/95 [==============================] - 375s 4s/step - loss: 0.4369 - accuracy: 0.8403 - precision: 0.8843 - recall: 0.7967 - val_loss: 0.2798 - val_accuracy: 0.9280 - val_precision: 0.9541 - val_recall: 0.9035\n",
      "Epoch 15/30\n",
      "95/95 [==============================] - 371s 4s/step - loss: 0.4145 - accuracy: 0.8579 - precision: 0.8995 - recall: 0.8170 - val_loss: 0.2870 - val_accuracy: 0.9266 - val_precision: 0.9481 - val_recall: 0.8927\n",
      "Epoch 16/30\n",
      "95/95 [==============================] - 423s 4s/step - loss: 0.4172 - accuracy: 0.8552 - precision: 0.8920 - recall: 0.8173 - val_loss: 0.2766 - val_accuracy: 0.9293 - val_precision: 0.9497 - val_recall: 0.8981\n",
      "Epoch 17/30\n",
      "95/95 [==============================] - 363s 4s/step - loss: 0.3886 - accuracy: 0.8622 - precision: 0.9040 - recall: 0.8193 - val_loss: 0.2706 - val_accuracy: 0.9266 - val_precision: 0.9513 - val_recall: 0.9022\n",
      "Epoch 18/30\n",
      "95/95 [==============================] - 365s 4s/step - loss: 0.3858 - accuracy: 0.8622 - precision: 0.9051 - recall: 0.8233 - val_loss: 0.2660 - val_accuracy: 0.9334 - val_precision: 0.9500 - val_recall: 0.9035\n",
      "Epoch 19/30\n",
      "95/95 [==============================] - 557s 6s/step - loss: 0.3872 - accuracy: 0.8645 - precision: 0.9049 - recall: 0.8276 - val_loss: 0.2644 - val_accuracy: 0.9321 - val_precision: 0.9516 - val_recall: 0.9090\n",
      "Epoch 20/30\n",
      "95/95 [==============================] - 352s 4s/step - loss: 0.3833 - accuracy: 0.8638 - precision: 0.9024 - recall: 0.8349 - val_loss: 0.2599 - val_accuracy: 0.9334 - val_precision: 0.9518 - val_recall: 0.9117\n",
      "Epoch 21/30\n",
      "95/95 [==============================] - 359s 4s/step - loss: 0.3788 - accuracy: 0.8632 - precision: 0.9014 - recall: 0.8260 - val_loss: 0.2529 - val_accuracy: 0.9361 - val_precision: 0.9504 - val_recall: 0.9117\n",
      "Epoch 22/30\n",
      "95/95 [==============================] - 374s 4s/step - loss: 0.3444 - accuracy: 0.8765 - precision: 0.9104 - recall: 0.8439 - val_loss: 0.2477 - val_accuracy: 0.9334 - val_precision: 0.9506 - val_recall: 0.9144\n",
      "Epoch 23/30\n",
      "95/95 [==============================] - 370s 4s/step - loss: 0.3509 - accuracy: 0.8745 - precision: 0.9128 - recall: 0.8452 - val_loss: 0.2389 - val_accuracy: 0.9389 - val_precision: 0.9576 - val_recall: 0.9198\n",
      "Epoch 24/30\n",
      "95/95 [==============================] - 416s 4s/step - loss: 0.3403 - accuracy: 0.8801 - precision: 0.9132 - recall: 0.8522 - val_loss: 0.2489 - val_accuracy: 0.9334 - val_precision: 0.9506 - val_recall: 0.9144\n",
      "Epoch 25/30\n",
      "95/95 [==============================] - 401s 4s/step - loss: 0.3449 - accuracy: 0.8758 - precision: 0.9094 - recall: 0.8432 - val_loss: 0.2463 - val_accuracy: 0.9348 - val_precision: 0.9505 - val_recall: 0.9130\n",
      "Epoch 26/30\n",
      "95/95 [==============================] - 387s 4s/step - loss: 0.3417 - accuracy: 0.8801 - precision: 0.9161 - recall: 0.8489 - val_loss: 0.2365 - val_accuracy: 0.9375 - val_precision: 0.9575 - val_recall: 0.9185\n",
      "Epoch 27/30\n",
      "95/95 [==============================] - 390s 4s/step - loss: 0.3223 - accuracy: 0.8854 - precision: 0.9209 - recall: 0.8585 - val_loss: 0.2354 - val_accuracy: 0.9361 - val_precision: 0.9550 - val_recall: 0.9226\n",
      "Epoch 28/30\n",
      "95/95 [==============================] - 395s 4s/step - loss: 0.3336 - accuracy: 0.8838 - precision: 0.9189 - recall: 0.8575 - val_loss: 0.2320 - val_accuracy: 0.9389 - val_precision: 0.9550 - val_recall: 0.9226\n",
      "Epoch 29/30\n",
      "95/95 [==============================] - 387s 4s/step - loss: 0.3201 - accuracy: 0.8914 - precision: 0.9194 - recall: 0.8602 - val_loss: 0.2293 - val_accuracy: 0.9402 - val_precision: 0.9563 - val_recall: 0.9226\n",
      "Epoch 30/30\n",
      "95/95 [==============================] - 377s 4s/step - loss: 0.3047 - accuracy: 0.8957 - precision: 0.9244 - recall: 0.8652 - val_loss: 0.2347 - val_accuracy: 0.9361 - val_precision: 0.9535 - val_recall: 0.9198\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "trainingAugmentation.flow(X_train, Y_train, batch_size=32),\n",
    "steps_per_epoch=len(X_train) // 32,\n",
    "validation_data=validationAugmentation.flow(X_test, Y_test),\n",
    "validation_steps = len(X_test)// 32,\n",
    "epochs=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(outputmodel)\n",
    "lbinarizer.close()lbinarizer = open(r\"Users/valeriyavishnevskaya/Desktop/test/video_classification/videoclassificationbinarizer.pickle\",\"wb\")\n",
    "lbinarizer.write(pickle.dumps(lb))\n",
    "lbinarizer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
